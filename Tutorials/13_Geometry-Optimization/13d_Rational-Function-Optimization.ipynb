{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rational Function Optimization\n",
    "\n",
    "Rational Function Optimization (RFO) is the method of choice for minimizations. This tutorial will walk through the basic theory of RFO and show a sample calculation.  The method was introduced for geometry optimizations by A. Banerjee, N. Adams, J. Simons, and R. Shepard in J. Phys. Chem. 89, 52(1985).\n",
    "\n",
    "In the Newton-Raphson method, the potential energy surface is approximated by the truncated Taylor expansion in internal coordinates $q$ and gradient $g$ (where vectors are interpreted as columns).\n",
    "\n",
    "$$ \\epsilon = E(q) - E_0 = g^T \\Delta q + \\frac{1}{2}(\\Delta q)^T \\mathbf{H} \\Delta q $$\n",
    "\n",
    "An extension is to express the potential via a [2/2] Pade approximation, where __S__ is the scaling matrix.  If __S__ were zero, then the harmonic approximation is obtained.\n",
    "\n",
    "$$ \\epsilon = \\frac{g^T\\Delta q + \\frac{1}{2} (\\Delta q)^T \\textbf{H} \\Delta q}{1 + \\Delta q^T \\textbf{S} \\Delta q} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relative energy expression can be rewritten in the form of $N+1$ dimensional vectors, where $N$ is the number of coordinates.\n",
    "\n",
    "$$ \\epsilon = \\frac{ \\frac{1}{2}\\begin{pmatrix} \\Delta{q^T} & 1\\end{pmatrix}\\begin{pmatrix} {\\textbf H} & g \\\\ g^T & 0  \\end{pmatrix}\\begin{pmatrix}\\Delta{q} \\\\ 1\\end{pmatrix} }{ \\begin{pmatrix} \\Delta q^T & 1 \\end{pmatrix} \\begin{pmatrix} \\textbf S & 0  \\\\ 0 & 1 \\end{pmatrix} \\begin{pmatrix} \\Delta q \\\\ 1 \\end{pmatrix}}$$\n",
    "\n",
    "since the right-hand side is\n",
    "\\begin{align}\n",
    "  &= \\frac{ \\frac{1}{2}\\begin{pmatrix} \\Delta{q^T} & 1\\end{pmatrix} \\begin{pmatrix} \\textbf{H} \\Delta q  + g \\\\ g^T \\Delta q + 0 \\end{pmatrix}}{\\begin{pmatrix} \\Delta q^T & 1 \\end{pmatrix} \\begin{pmatrix} \\textbf S \\Delta q + 0 \\\\ 0 + 1 \\end{pmatrix}} \\\\\n",
    "  \\\\\n",
    " &= \\frac { \\frac{1}{2} \\Delta q^T \\textbf H \\Delta q + \\frac{1}{2} \\Delta q^T g + \\frac{1}{2} g^T \\Delta q} { \\Delta q^T\\textbf S \\Delta q + 1}\n",
    " \\\\\n",
    "\\end{align}\n",
    "which is equivalent to the expression above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the stationary point assumption that  \n",
    "$$\\frac{\\partial \\epsilon}{\\partial q } = 0 $$\n",
    "we can derive the expression for the step.\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial \\epsilon}{\\partial q} &= \\frac {g + \\mathbf{H} \\Delta q}{1 + \\Delta q^T \\textbf S \\Delta q} - \\frac{ g \\Delta q^T + \\frac{1}{2} \\Delta q^T \\textbf H \\Delta q}{ 1 + \\Delta q^T \\textbf S \\Delta q} \\Big( \\frac{ 2 \\textbf S \\Delta q}{1 + \\Delta q^T \\textbf S \\Delta q}\\Big) \\\\\n",
    "\\\\\n",
    "\\frac{\\partial \\epsilon}{\\partial q} &= \\frac {g + \\textbf{H}\\Delta q}{1 + \\Delta q^T \\textbf S \\Delta q} - \\epsilon \\Big( \\frac{ 2 \\textbf S \\Delta q}{1 + \\Delta q^T \\textbf S \\Delta q} \\Big) \\\\\n",
    "\\\\\n",
    "0 &= \\frac{ g + \\textbf{H} \\Delta q - 2 \\epsilon \\textbf S \\Delta q}{1 + \\Delta q^T \\textbf S \\Delta q}\\\\\n",
    "\\\\\n",
    "0 &=  g + \\textbf{H} \\Delta q - 2 \\epsilon \\textbf S \\Delta q \\\\\n",
    "\\\\\n",
    "g + H\\Delta q &= 2 \\epsilon \\textbf S \\Delta q = \\lambda \\textbf S \\Delta q\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\lambda$ is defined as $2\\epsilon$.  It can be shown that \n",
    "$$\\lambda = g^T \\Delta q$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which allows the stationarity condition to be written as follows.\n",
    "\n",
    "\\begin{align}\n",
    "\\begin{pmatrix} \\textbf H \\Delta q \\\\ g^T \\Delta q \\end{pmatrix} + \\begin{pmatrix} g \\\\ 0 \\end{pmatrix} &= \\begin{pmatrix} \\lambda \\textbf S \\Delta q \\\\ \\lambda \\end{pmatrix} \\\\\n",
    "\\textrm{or} \\\\\n",
    "\\begin{pmatrix} \\textbf H & g \\\\ g^T & 0 \\end{pmatrix} \\begin{pmatrix} \\Delta q \\\\ 1 \\end{pmatrix} &= \\lambda \\begin{pmatrix} {\\textbf{S} \\Delta q} \\\\ 1 \\end{pmatrix} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The matrix __S__ is usually taken to be the identify matrix.  The result is an eigenvalue equation with $\\lambda$ as the eigenvalue!\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix} \\textbf H & g \\\\ g^T & 0 \\end{pmatrix}\n",
    "\\begin{pmatrix} \\Delta q \\\\ 1 \\end{pmatrix} = \\lambda \\begin{pmatrix} { \\Delta q} \\\\ 1 \\end{pmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $N+1$ dimensional matrix on the left is called the \"RFO matrix\".  We build it from our Hessian and our gradient in internal coordinates.  Then the eigenvectors and eigenvalues of this matrix are determined.  For minimum-energy searches, we usually choose the eigenvector with the lowest value of $\\lambda$.  This value is hopefully negative, and is 2 times the  energy change anticipated from the step.  This eigenvector is intermediate-normalized by scaling the last element to 1.  The rest of the vector is the desired RFO step, or displacement in internal coordinates.\n",
    "\n",
    "Occasionally, this eigenvector has a very small final element, and cannot be intermediate normalized.  This comes about, for example, when the step breaks molecular symmetry and the projected energy change may be zero.  Also, the algorithm is numerically problematic if the gradients are very small.\n",
    "\n",
    "In practice, RFO performs better than ordinary Newton-Raphson steps if the energy surface being explored is not very harmonic, or if the optimization is begun far from a minimum.  However, if the potential surface is nearly flat (e.g., methane dimer), then RFO like ordinary N-R, will perform poorly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import psi4\n",
    "from optking import optParams as op\n",
    "from optking import printTools\n",
    "printTools.printInit(printTools.cleanPrint)\n",
    "mol = psi4.molecule (\"\"\"\n",
    "  H     0.0000000000   0.9803530335  -0.8498671785\n",
    "  O     0.0000000000   0.6988545188   0.0536419016\n",
    "  O     0.0000000000  -0.6988545188   0.0536419016\n",
    "  H     0.0000000000  -0.9803530335  -0.8498671785\n",
    "\"\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Partioned-RFO method is an extension of the RFO method, and may be used to seek non-minima stationary points such as transition states.  In the P-RFO method, there are two RFO matrices.  We maximize along 1 or more degrees of freedom while minimizing along the others.\n",
    "\n",
    "An extended scheme to limit the RFO step size may be found in\n",
    "Besalu and Bofill, Theor. Chem. Acc., 1999, 100:265-274\n",
    "E. Besalu and J.M. Bofill, Theor. Chem. Acc  100 (1998) 265."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
